{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import tensorflow_text as tf_text\n",
    "import nltk\n",
    "\n",
    "from official.nlp import optimization\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = pd.read_excel(\"../../data/labeled_dataset.xlsx\").rename(columns={\"Unnamed: 0\": \"id\"})\n",
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df[\"Label_opinion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minified_df = labeled_df[[\"sentence\", \"Label_opinion\"]]\n",
    "minified_df[\"target\"] = (minified_df[\"Label_opinion\"] == \"Expresses writer’s opinion\").astype(int)\n",
    "minified_df = minified_df.drop(\"Label_opinion\", axis=1)\n",
    "minified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (minified_df['sentence'].values, minified_df['target'].values)\n",
    "    )\n",
    "    .shuffle(minified_df.shape[0])\n",
    "    .batch(32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_layer = tf_hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    name=\"preprocessing\"\n",
    ")\n",
    "\n",
    "encoder_layer = tf_hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/2\",\n",
    "    name=\"BERT_encoder\",\n",
    "    trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(preprocess_layer, encoder_layer):\n",
    "    input_layer = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input\")\n",
    "    preprocessing_layer = preprocess_layer(input_layer)\n",
    "    encoder_outputs = encoder_layer(preprocessing_layer)\n",
    "    pooled_output = encoder_outputs[\"pooled_output\"]\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(pooled_output)\n",
    "    model = tf.keras.Model(input_layer, output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(preprocess_layer, encoder_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "epochs = 20\n",
    "steps_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=init_lr,\n",
    "    num_train_steps=num_train_steps,    \n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    optimizer_type='adamw'\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,  \n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=dataset,\n",
    "    epochs=epochs\n",
    ")\n",
    "model.save_weights(\"../models/small_bert_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "plt.plot(history_dict['loss'], label='loss')\n",
    "plt.plot(history_dict['binary_accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../models/small_bert_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([\n",
    "    \"As reported by the police\", \n",
    "    \"I would say that the police is not doing a good job\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/small_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"../models/small_bert_model\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([\n",
    "    \"The government made a decision to cut military spending\", \n",
    "    \"The government made a dumb decision to cut military spending\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "Meanwhile, the Democratic National Committee (DNC) doesn’t have any primary debates scheduled – a move that helps President Joe Biden and hurts his challengers Robert F. Kennedy Jr. and Marianne Williamson. It’s clear the DNC doesn’t see Kennedy or Williamson as serious contenders, and Biden seems to prefer a Rose Garden strategy, where the focus of his campaign revolves around being the president and showing the country how he does the job.\n",
    "Having fewer debates, however, is not necessarily a bad thing. But quantity is not the issue here. Quality is.\n",
    "Of course, the number of debates for each party is subject to change. Trump, for instance, could simply be bluffing to add some intrigue. And a more serious Biden challenger could enter the race, prompting the DNC to schedule a debate.\n",
    "But, at this rate, it’s possible that the debates will play a much smaller role in 2024 than they did in 2016 or in 2020. And if the two parties end up nominating Biden and Trump, many Americans may also choose to tune out any debates, thinking they are already quite familiar with both candidates.\n",
    "That would be a departure from the norm, since debates have been a big part of presidential politics since World War II. Richard Nixon famously squared off against John F. Kennedy in 1960, with an estimated 70 million Americans tuning in to the first of a series of live televised debates between the two major presidential candidates. Nixon seemed nervous and sickly next to the young senator, whose charisma and good looks became the stuff of TV legend.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = nltk.sent_tokenize(test_article)\n",
    "detected_bias = model.predict(test_sentences)\n",
    "\n",
    "# for sentence, bias in zip(test_sentences, detected_bias):\n",
    "#     print(f\"{sentence}: {bias[0]}\")\n",
    "detected_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(text):\n",
    "    prob = model.predict([text])\n",
    "    return np.hstack([1 - prob, prob])\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=[\"Non-biased\", \"Biased\"])\n",
    "explanation = explainer.explain_instance(test_article, get_probabilities, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, bias in zip(test_sentences, detected_bias):\n",
    "    explainer.explain_instance(sentence, get_probabilities, num_features=10).show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
