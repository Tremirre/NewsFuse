{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "import wandb\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import nltk\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "from train_wandb import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Endrj\\AppData\\Local\\Temp\\ipykernel_24872\\641006522.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  minified_df[\"target\"] = (minified_df[\"Label_opinion\"] == \"Expresses writer’s opinion\").astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YouTube is making clear there will be no “birt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The increasingly bitter dispute between Americ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So while there may be a humanitarian crisis dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A professor who teaches climate change classes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Looking around the United States, there is nev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  target\n",
       "0  YouTube is making clear there will be no “birt...       0\n",
       "1  The increasingly bitter dispute between Americ...       0\n",
       "2  So while there may be a humanitarian crisis dr...       1\n",
       "3  A professor who teaches climate change classes...       0\n",
       "4  Looking around the United States, there is nev...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df = pd.read_excel(\"../../data/labeled_dataset.xlsx\").rename(columns={\"Unnamed: 0\": \"id\"})\n",
    "minified_df = labeled_df[[\"sentence\", \"Label_opinion\"]]\n",
    "minified_df[\"target\"] = (minified_df[\"Label_opinion\"] == \"Expresses writer’s opinion\").astype(int)\n",
    "minified_df = minified_df.drop(\"Label_opinion\", axis=1)\n",
    "minified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A set of tests specifically for Congo fever we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By afternoon she was conversing with her husba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although the woman's condition had deteriorate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The patient told hospital authorities she beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She also had a skin rash and was vomiting.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  target\n",
       "0  A set of tests specifically for Congo fever we...       0\n",
       "1  By afternoon she was conversing with her husba...       0\n",
       "2  Although the woman's condition had deteriorate...       0\n",
       "3  The patient told hospital authorities she beca...       0\n",
       "4         She also had a skin rash and was vomiting.       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpqa_df = pd.read_csv(\"../../data/mpqa_filtered.csv\", sep = \";\").rename(columns={\"sent\": \"sentence\"})\n",
    "mpqa_df[\"target\"] = np.where(mpqa_df['score'] >= 2, 1, 0)\n",
    "mpqa_df.drop(columns=[\"score\"], inplace = True)\n",
    "mpqa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_df = pd.concat([minified_df, mpqa_df])\n",
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (full_dataset_df['sentence'].values, full_dataset_df['target'].values)\n",
    "    )\n",
    "    .shuffle(full_dataset_df.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_opinion_text = \"\"\"\n",
    "Natural language processing (NLP) is an interdisciplinary subfield of linguistics, computer science, \n",
    "and artificial intelligence concerned with the interactions between computers and human language, \n",
    "in particular how to program computers to process and analyze large amounts of natural language data. \n",
    "The goal is a computer capable of understanding the contents of documents, \n",
    "including the contextual nuances of the language within them. The technology can then accurately extract \n",
    "information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_text = \"\"\"\n",
    "One of my favourite films is Titanic. I`m a great fan of romantic movies and I`m very keen on the history of the tragic Titanic. \n",
    "The movie tells the dramatic story of the Titanic with Leonardo Di Caprio and Kate Winslet as the main actors.\n",
    "In the year 1912 a young poor guy, Leonardo, travels by the gorgeous ship Titanic from London to New York with a big dream. \n",
    "On board he meets a fabulous, wealthy girl, Kate Winslet. He fells in love with her as soon as he sees this gorgeous girl. \n",
    "However, after a few days the ship hits an enormous iceberg and the tragedy begins to unfold. The Titanic starts sinking…\n",
    "The movie is very close to the real tragedy. It shows a beautiful love story with an extremely sad ending. \n",
    "The acting is first-rate. Leonardo Di Caprio`s and Kate Winslet`s performance is so brilliant that I cried during the whole movie.\n",
    "This movie brings a tear to your eyes. If you want to cry and melt down to a glamurous love story, \n",
    "I strongly recommend that you watch this movie. Titanic is well worth seeing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(preprocess_layer, encoder_layer):\n",
    "    input_layer = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input\")\n",
    "    preprocessing_layer = preprocess_layer(input_layer)\n",
    "    encoder_outputs = encoder_layer(preprocessing_layer)\n",
    "    pooled_output = encoder_outputs[\"pooled_output\"]\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(pooled_output)\n",
    "    model = tf.keras.Model(input_layer, output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(config, name):\n",
    "    \n",
    "    preprocess_layer = tf_hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "        name=\"preprocessing\"\n",
    "    )\n",
    "\n",
    "    encoder_layer = tf_hub.KerasLayer(\n",
    "        \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/2\",\n",
    "        name=\"BERT_encoder\",\n",
    "        trainable=True\n",
    "    )\n",
    "\n",
    "    model = build_model(preprocess_layer, encoder_layer)\n",
    "    model.summary()\n",
    "\n",
    "    trainer = Trainer(config,model,dataset, name)\n",
    "    trainer.compile_model()\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    trainer.test_model()\n",
    "    trainer.predict_model(no_opinion_text, \"no opinion text\")\n",
    "    trainer.predict_model(opinion_text, \"opinion text\")\n",
    "\n",
    "    def get_probabilities(text):\n",
    "        prob = model.predict([text])\n",
    "        return np.hstack([1 - prob, prob])\n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=[\"Non-biased\", \"Biased\"])\n",
    "    explanation_2 = trainer.explain_prediction(no_opinion_text, \"No opinion text explanation\")\n",
    "    explanation_1 = trainer.explain_prediction(opinion_text,  \"Opinion text explanation\")\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        explanation_1.show_in_notebook(text=True)\n",
    "        explanation_2.show_in_notebook(text=True)\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"architecture\": \"bigger-BERT-CNN\",\n",
    "    \"dataset\": \"full_dataset\",\n",
    "    \"datasize\": minified_df.shape[0],\n",
    "    \"epochs\": 50,\n",
    "    \"steps_per_epoch\": tf.data.experimental.cardinality(dataset).numpy(),\n",
    "    \"num_train_steps\": tf.data.experimental.cardinality(dataset).numpy() * 20,\n",
    "    \"num_warmup_steps\": int(0.1 * tf.data.experimental.cardinality(dataset).numpy() * 20),\n",
    "    \"init_lr\": 3e-5,\n",
    "    \"batch_size\" : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_table = [1,2,4,8,16,32,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_table = [3e-6, 1e-5, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['input[0][0]']                  \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'default': (None,   53982721    ['preprocessing[0][0]',          \n",
      "                                512),                             'preprocessing[0][1]',          \n",
      "                                 'pooled_output': (               'preprocessing[0][2]']          \n",
      "                                None, 512),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)]}                                               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            513         ['BERT_encoder[0][13]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 53,983,234\n",
      "Trainable params: 53,983,233\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandrzej-kajdasz\u001b[0m (\u001b[33mput_dl_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Endrj\\OneDrive\\Pulpit\\NewsFuse\\newsfuse-func\\notebooks\\wandb\\run-20230614_152214-550dxozx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/put_dl_team/news-fuse/runs/550dxozx\" target=\"_blank\">Experiment-bigger-BERT</a></strong> to <a href=\"https://wandb.ai/put_dl_team/news-fuse\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Endrj\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Endrj\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1530/1530 [==============================] - 167s 97ms/step - loss: 0.8609 - binary_accuracy: 0.5752 - val_loss: 0.7262 - val_binary_accuracy: 0.6471 - _timestamp: 1686749111.0000 - _runtime: 177.0000\n",
      "Epoch 2/50\n",
      "1530/1530 [==============================] - 163s 106ms/step - loss: 0.9093 - binary_accuracy: 0.7039 - val_loss: 1.1120 - val_binary_accuracy: 0.7294 - _timestamp: 1686749274.0000 - _runtime: 340.0000\n",
      "Epoch 3/50\n",
      "1530/1530 [==============================] - 149s 97ms/step - loss: 0.9926 - binary_accuracy: 0.7752 - val_loss: 1.4494 - val_binary_accuracy: 0.7059 - _timestamp: 1686749423.0000 - _runtime: 489.0000\n",
      "Epoch 4/50\n",
      "1530/1530 [==============================] - 154s 100ms/step - loss: 1.0578 - binary_accuracy: 0.7627 - val_loss: 0.8031 - val_binary_accuracy: 0.8353 - _timestamp: 1686749576.0000 - _runtime: 642.0000\n",
      "Epoch 5/50\n",
      "1530/1530 [==============================] - 179s 117ms/step - loss: 0.9878 - binary_accuracy: 0.7837 - val_loss: 0.6475 - val_binary_accuracy: 0.8471 - _timestamp: 1686749756.0000 - _runtime: 822.0000\n",
      "Epoch 6/50\n",
      "1530/1530 [==============================] - 193s 126ms/step - loss: 0.9234 - binary_accuracy: 0.8026 - val_loss: 0.9654 - val_binary_accuracy: 0.7882 - _timestamp: 1686749949.0000 - _runtime: 1015.0000\n",
      "Epoch 7/50\n",
      "1530/1530 [==============================] - 180s 118ms/step - loss: 0.9061 - binary_accuracy: 0.8137 - val_loss: 0.9996 - val_binary_accuracy: 0.7765 - _timestamp: 1686750129.0000 - _runtime: 1195.0000\n",
      "Epoch 8/50\n",
      "1530/1530 [==============================] - 185s 121ms/step - loss: 0.8747 - binary_accuracy: 0.8170 - val_loss: 0.8985 - val_binary_accuracy: 0.8118 - _timestamp: 1686750314.0000 - _runtime: 1380.0000\n",
      "Epoch 9/50\n",
      "1530/1530 [==============================] - 193s 126ms/step - loss: 0.9430 - binary_accuracy: 0.8085 - val_loss: 0.7097 - val_binary_accuracy: 0.8588 - _timestamp: 1686750508.0000 - _runtime: 1574.0000\n",
      "Epoch 10/50\n",
      "1530/1530 [==============================] - 195s 127ms/step - loss: 0.8271 - binary_accuracy: 0.8307 - val_loss: 0.8650 - val_binary_accuracy: 0.8706 - _timestamp: 1686750703.0000 - _runtime: 1769.0000\n",
      "Epoch 11/50\n",
      "1530/1530 [==============================] - 195s 127ms/step - loss: 0.8132 - binary_accuracy: 0.8392 - val_loss: 0.3681 - val_binary_accuracy: 0.9176 - _timestamp: 1686750898.0000 - _runtime: 1964.0000\n",
      "Epoch 12/50\n",
      "1530/1530 [==============================] - 190s 124ms/step - loss: 0.8133 - binary_accuracy: 0.8418 - val_loss: 0.5958 - val_binary_accuracy: 0.8824 - _timestamp: 1686751088.0000 - _runtime: 2154.0000\n",
      "Epoch 13/50\n",
      "1530/1530 [==============================] - 176s 115ms/step - loss: 0.7761 - binary_accuracy: 0.8490 - val_loss: 0.7301 - val_binary_accuracy: 0.8706 - _timestamp: 1686751263.0000 - _runtime: 2329.0000\n",
      "Epoch 14/50\n",
      "1530/1530 [==============================] - 182s 119ms/step - loss: 0.8131 - binary_accuracy: 0.8412 - val_loss: 0.5828 - val_binary_accuracy: 0.8824 - _timestamp: 1686751445.0000 - _runtime: 2511.0000\n",
      "Epoch 15/50\n",
      "1530/1530 [==============================] - 186s 122ms/step - loss: 0.7577 - binary_accuracy: 0.8477 - val_loss: 0.4415 - val_binary_accuracy: 0.9176 - _timestamp: 1686751631.0000 - _runtime: 2697.0000\n",
      "Epoch 16/50\n",
      "1530/1530 [==============================] - 172s 112ms/step - loss: 0.6858 - binary_accuracy: 0.8621 - val_loss: 0.5169 - val_binary_accuracy: 0.8824 - _timestamp: 1686751803.0000 - _runtime: 2869.0000\n",
      "Epoch 17/50\n",
      "1530/1530 [==============================] - 192s 125ms/step - loss: 0.8191 - binary_accuracy: 0.8314 - val_loss: 0.7507 - val_binary_accuracy: 0.8471 - _timestamp: 1686751995.0000 - _runtime: 3061.0000\n",
      "Epoch 18/50\n",
      "1530/1530 [==============================] - 185s 121ms/step - loss: 0.7284 - binary_accuracy: 0.8536 - val_loss: 1.2709 - val_binary_accuracy: 0.7647 - _timestamp: 1686752180.0000 - _runtime: 3246.0000\n",
      "Epoch 19/50\n",
      "1530/1530 [==============================] - 217s 142ms/step - loss: 0.7753 - binary_accuracy: 0.8386 - val_loss: 0.4925 - val_binary_accuracy: 0.9059 - _timestamp: 1686752397.0000 - _runtime: 3463.0000\n",
      "Epoch 20/50\n",
      "1530/1530 [==============================] - 172s 112ms/step - loss: 0.7636 - binary_accuracy: 0.8359 - val_loss: 0.6268 - val_binary_accuracy: 0.8824 - _timestamp: 1686752569.0000 - _runtime: 3635.0000\n",
      "Epoch 21/50\n",
      "1530/1530 [==============================] - 172s 112ms/step - loss: 0.7927 - binary_accuracy: 0.8288 - val_loss: 0.4881 - val_binary_accuracy: 0.9059 - _timestamp: 1686752741.0000 - _runtime: 3807.0000\n",
      "Epoch 22/50\n",
      "1530/1530 [==============================] - 376s 246ms/step - loss: 0.7690 - binary_accuracy: 0.8216 - val_loss: 0.7564 - val_binary_accuracy: 0.8000 - _timestamp: 1686753117.0000 - _runtime: 4183.0000\n",
      "Epoch 23/50\n",
      "1530/1530 [==============================] - 173s 113ms/step - loss: 0.7170 - binary_accuracy: 0.8386 - val_loss: 0.8613 - val_binary_accuracy: 0.8353 - _timestamp: 1686753289.0000 - _runtime: 4355.0000\n",
      "Epoch 24/50\n",
      "1530/1530 [==============================] - 181s 118ms/step - loss: 0.7414 - binary_accuracy: 0.8405 - val_loss: 0.8719 - val_binary_accuracy: 0.8235 - _timestamp: 1686753470.0000 - _runtime: 4536.0000\n",
      "Epoch 25/50\n",
      "1530/1530 [==============================] - 174s 114ms/step - loss: 0.7087 - binary_accuracy: 0.8608 - val_loss: 1.0043 - val_binary_accuracy: 0.8118 - _timestamp: 1686753645.0000 - _runtime: 4711.0000\n",
      "Epoch 26/50\n",
      "1530/1530 [==============================] - 170s 111ms/step - loss: 0.7309 - binary_accuracy: 0.8497 - val_loss: 1.0482 - val_binary_accuracy: 0.8118 - _timestamp: 1686753815.0000 - _runtime: 4881.0000\n",
      "Epoch 27/50\n",
      "1530/1530 [==============================] - 178s 116ms/step - loss: 0.7219 - binary_accuracy: 0.8503 - val_loss: 1.0004 - val_binary_accuracy: 0.7882 - _timestamp: 1686753992.0000 - _runtime: 5058.0000\n",
      "Epoch 28/50\n",
      "1530/1530 [==============================] - 178s 116ms/step - loss: 0.9184 - binary_accuracy: 0.7843 - val_loss: 1.0591 - val_binary_accuracy: 0.7529 - _timestamp: 1686754170.0000 - _runtime: 5236.0000\n",
      "Epoch 29/50\n",
      "1530/1530 [==============================] - 172s 112ms/step - loss: 0.7811 - binary_accuracy: 0.8327 - val_loss: 0.6362 - val_binary_accuracy: 0.8706 - _timestamp: 1686754342.0000 - _runtime: 5408.0000\n",
      "Epoch 30/50\n",
      "1530/1530 [==============================] - 172s 112ms/step - loss: 0.8327 - binary_accuracy: 0.8065 - val_loss: 0.7492 - val_binary_accuracy: 0.8235 - _timestamp: 1686754514.0000 - _runtime: 5580.0000\n",
      "Epoch 31/50\n",
      "1530/1530 [==============================] - 172s 112ms/step - loss: 0.7133 - binary_accuracy: 0.8333 - val_loss: 0.6337 - val_binary_accuracy: 0.8706 - _timestamp: 1686754686.0000 - _runtime: 5752.0000\n",
      "Epoch 32/50\n",
      "1530/1530 [==============================] - 169s 111ms/step - loss: 0.7468 - binary_accuracy: 0.8366 - val_loss: 0.6188 - val_binary_accuracy: 0.8706 - _timestamp: 1686754855.0000 - _runtime: 5921.0000\n",
      "Epoch 33/50\n",
      "1530/1530 [==============================] - 163s 107ms/step - loss: 0.8416 - binary_accuracy: 0.8144 - val_loss: 0.7993 - val_binary_accuracy: 0.8235 - _timestamp: 1686755018.0000 - _runtime: 6084.0000\n",
      "Epoch 34/50\n",
      "1530/1530 [==============================] - 410s 268ms/step - loss: 0.8787 - binary_accuracy: 0.8039 - val_loss: 0.6790 - val_binary_accuracy: 0.8588 - _timestamp: 1686755428.0000 - _runtime: 6494.0000\n",
      "Epoch 35/50\n",
      "1530/1530 [==============================] - 164s 107ms/step - loss: 0.8710 - binary_accuracy: 0.8059 - val_loss: 1.2262 - val_binary_accuracy: 0.7059 - _timestamp: 1686755593.0000 - _runtime: 6659.0000\n",
      "Epoch 36/50\n",
      "1530/1530 [==============================] - 167s 109ms/step - loss: 0.8031 - binary_accuracy: 0.8261 - val_loss: 0.5390 - val_binary_accuracy: 0.8941 - _timestamp: 1686755760.0000 - _runtime: 6826.0000\n",
      "Epoch 37/50\n",
      "1530/1530 [==============================] - 161s 105ms/step - loss: 0.7920 - binary_accuracy: 0.8327 - val_loss: 0.7810 - val_binary_accuracy: 0.8471 - _timestamp: 1686755921.0000 - _runtime: 6987.0000\n",
      "Epoch 38/50\n",
      "1530/1530 [==============================] - 294s 192ms/step - loss: 0.7462 - binary_accuracy: 0.8484 - val_loss: 0.8017 - val_binary_accuracy: 0.8000 - _timestamp: 1686756215.0000 - _runtime: 7281.0000\n",
      "Epoch 39/50\n",
      "1530/1530 [==============================] - 172s 113ms/step - loss: 1.1015 - binary_accuracy: 0.7248 - val_loss: 0.9998 - val_binary_accuracy: 0.7529 - _timestamp: 1686756387.0000 - _runtime: 7453.0000\n",
      "Epoch 40/50\n",
      "1530/1530 [==============================] - 166s 108ms/step - loss: 0.8107 - binary_accuracy: 0.8235 - val_loss: 0.9183 - val_binary_accuracy: 0.8118 - _timestamp: 1686756553.0000 - _runtime: 7619.0000\n",
      "Epoch 41/50\n",
      "1530/1530 [==============================] - 162s 106ms/step - loss: 0.8735 - binary_accuracy: 0.7993 - val_loss: 0.7455 - val_binary_accuracy: 0.8118 - _timestamp: 1686756715.0000 - _runtime: 7781.0000\n",
      "Epoch 42/50\n",
      "1530/1530 [==============================] - 648s 424ms/step - loss: 0.7893 - binary_accuracy: 0.8301 - val_loss: 0.6956 - val_binary_accuracy: 0.8471 - _timestamp: 1686757363.0000 - _runtime: 8429.0000\n",
      "Epoch 43/50\n",
      "1530/1530 [==============================] - 169s 111ms/step - loss: 0.9134 - binary_accuracy: 0.7967 - val_loss: 0.9016 - val_binary_accuracy: 0.7765 - _timestamp: 1686757532.0000 - _runtime: 8598.0000\n",
      "Epoch 44/50\n",
      "1530/1530 [==============================] - 169s 111ms/step - loss: 0.9649 - binary_accuracy: 0.7725 - val_loss: 0.6838 - val_binary_accuracy: 0.8588 - _timestamp: 1686757702.0000 - _runtime: 8768.0000\n",
      "Epoch 45/50\n",
      "1530/1530 [==============================] - 166s 108ms/step - loss: 1.0071 - binary_accuracy: 0.7412 - val_loss: 1.0278 - val_binary_accuracy: 0.6588 - _timestamp: 1686757868.0000 - _runtime: 8934.0000\n",
      "Epoch 46/50\n",
      "1530/1530 [==============================] - 169s 111ms/step - loss: 0.9066 - binary_accuracy: 0.7850 - val_loss: 1.3414 - val_binary_accuracy: 0.6588 - _timestamp: 1686758037.0000 - _runtime: 9103.0000\n",
      "Epoch 47/50\n",
      "1530/1530 [==============================] - 169s 110ms/step - loss: 1.0812 - binary_accuracy: 0.7150 - val_loss: 0.9877 - val_binary_accuracy: 0.6941 - _timestamp: 1686758206.0000 - _runtime: 9272.0000\n",
      "Epoch 48/50\n",
      "1530/1530 [==============================] - 169s 110ms/step - loss: 0.8994 - binary_accuracy: 0.7869 - val_loss: 1.0117 - val_binary_accuracy: 0.7765 - _timestamp: 1686758375.0000 - _runtime: 9441.0000\n",
      "Epoch 49/50\n",
      "1530/1530 [==============================] - 169s 111ms/step - loss: 0.9164 - binary_accuracy: 0.7863 - val_loss: 0.8250 - val_binary_accuracy: 0.8118 - _timestamp: 1686758544.0000 - _runtime: 9610.0000\n",
      "Epoch 50/50\n",
      "1530/1530 [==============================] - 172s 113ms/step - loss: 0.9448 - binary_accuracy: 0.7889 - val_loss: 1.0390 - val_binary_accuracy: 0.7647 - _timestamp: 1686758716.0000 - _runtime: 9782.0000\n",
      "11721/11721 [==============================] - 312s 27ms/step - loss: 0.8650 - binary_accuracy: 0.8030\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "make_experiment(config, f\"Experiment-bigger-BERT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
